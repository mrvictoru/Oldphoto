{
  "6": {
    "inputs": {
      "text": "Restore an old photograph: repair scratches, reduce noise, remove compression artifacts, recover fine details and textures. Preserve identity, facial features, pose, composition, and lighting. Maintain realism and period-accurate appearance. No stylization.\n\nColorize realistically with natural skin tones, hair, textiles, foliage, sky, and materials. Avoid over-saturation. Respect original luminance and contrast. When ambiguous, choose plausible colors.\n\nEnhance clarity slightly while retaining authentic grain. Avoid plastic skin or over-sharpening.",
      "clip": [
        "210",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "27": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "51": {
    "inputs": {
      "seed": 330701147327264,
      "steps": 20,
      "cfg": 1,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.8000000000000002,
      "model": [
        "209",
        0
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "195",
        0
      ],
      "latent_image": [
        "110",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "100": {
    "inputs": {
      "upscale_model": [
        "101",
        0
      ],
      "image": [
        "168",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "101": {
    "inputs": {
      "model_name": "4x-ClearRealityV1.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "102": {
    "inputs": {
      "upscale_method": "lanczos",
      "scale_by": 0.5,
      "image": [
        "100",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "110": {
    "inputs": {
      "pixels": [
        "102",
        0
      ],
      "vae": [
        "27",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "111": {
    "inputs": {
      "samples": [
        "51",
        0
      ],
      "vae": [
        "27",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "144": {
    "inputs": {
      "anything": [
        "111",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "163": {
    "inputs": {
      "seed": 1000,
      "steps": 20,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "209",
        0
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "195",
        0
      ],
      "latent_image": [
        "188",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "164": {
    "inputs": {
      "samples": [
        "163",
        0
      ],
      "vae": [
        "27",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "168": {
    "inputs": {
      "anything": [
        "164",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "170": {
    "inputs": {
      "filename_prefix": "UP",
      "images": [
        "111",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image UPSCALED"
    }
  },
  "171": {
    "inputs": {
      "filename_prefix": "img",
      "images": [
        "164",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image Original"
    }
  },
  "188": {
    "inputs": {
      "pixels": [
        "196",
        0
      ],
      "vae": [
        "27",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "194": {
    "inputs": {
      "conditioning": [
        "6",
        0
      ],
      "latent": [
        "188",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "195": {
    "inputs": {
      "conditioning": [
        "6",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "196": {
    "inputs": {
      "image": [
        "__UPLOAD_FILENAME__"
      ]
    },
    "class_type": "FluxKontextImageScale",
    "_meta": {
      "title": "FluxKontextImageScale"
    }
  },
  "201": {
    "inputs": {
      "images": [
        "196",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image Scale"
    }
  },
  "203": {
    "inputs": {
      "image": "__UPLOAD_FILENAME__"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "209": {
    "inputs": {
      "unet_name": "flux1-kontext-dev-Q6_K.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "210": {
    "inputs": {
      "clip_name1": "t5-v1_1-xxl-encoder-Q4_K_S.gguf",
      "clip_name2": "clip_l.safetensors",
      "type": "flux"
    },
    "class_type": "DualCLIPLoaderGGUF",
    "_meta": {
      "title": "DualCLIPLoader (GGUF)"
    }
  }
}
